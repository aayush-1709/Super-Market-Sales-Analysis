{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"SuperMarket.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "segment_counts = df['Segment'].value_counts()\n",
    "print(segment_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "country_counts = df['Country/Region'].value_counts()\n",
    "print(country_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "city_counts = df['City'].value_counts() \n",
    "print(city_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Danbury_order = df[df['City'] == 'Danbury'].to_string(index=False)\n",
    "print(Danbury_order)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "postal_code_count = df['Postal Code'].value_counts()\n",
    "print(postal_code_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "postal = df[df['Postal Code']== '10035']\n",
    "print(postal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df['Category'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Order Date'] = pd.to_datetime(df['Order Date'], format='%d-%m-%Y')  # Specify the format\n",
    "df['Day'] = df['Order Date'].dt.day\n",
    "df['Month'] = df['Order Date'].dt.month\n",
    "df['Year'] = df['Order Date'].dt.year\n",
    "# print(df['Day'].head())\n",
    "# print(df['Month'].head())\n",
    "# print(df['Year'].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df[df['Sales']  > 600])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df['Sales'].max())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Descriptive Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Total and average sales by region, category, and segment\n",
    "region_sales = df.groupby('Region')['Sales'].agg(['sum', 'mean']).reset_index()\n",
    "category_sales = df.groupby('Category')['Sales'].agg(['sum', 'mean']).reset_index()\n",
    "segment_sales = df.groupby('Segment')['Sales'].agg(['sum', 'mean']).reset_index()\n",
    "\n",
    "# Convert Order Date to datetime for trend analysis\n",
    "df['Order Date'] = pd.to_datetime(df['Order Date'])\n",
    "\n",
    "# Group by month and calculate total sales and profit\n",
    "trend_data = df.resample('M', on='Order Date').agg({'Sales': 'sum', 'Profit': 'sum'}).reset_index()\n",
    "\n",
    "region_sales, category_sales, segment_sales, trend_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Customer Segmentation: Use clustering (e.g., K-Means) to group customers based on purchase behavior."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Prepare the data for clustering: Group by Customer ID and calculate aggregated metrics\n",
    "customer_data = df.groupby('Customer ID').agg({\n",
    "    'Sales': 'sum',\n",
    "    'Profit': 'sum',\n",
    "    'Quantity': 'sum'\n",
    "}).reset_index()\n",
    "\n",
    "# Standardize the data for clustering\n",
    "scaler = StandardScaler()\n",
    "scaled_data = scaler.fit_transform(customer_data[['Sales', 'Profit', 'Quantity']])\n",
    "\n",
    "# Apply K-Means clustering\n",
    "kmeans = KMeans(n_clusters=3, random_state=42)\n",
    "customer_data['Cluster'] = kmeans.fit_predict(scaled_data)\n",
    "\n",
    "# Show resulting clusters and the first few rows\n",
    "customer_clusters = customer_data.groupby('Cluster').agg({\n",
    "    'Sales': ['mean', 'sum'],\n",
    "    'Profit': ['mean', 'sum'],\n",
    "    'Quantity': ['mean', 'sum']\n",
    "}).reset_index()\n",
    "\n",
    "customer_data, customer_clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cus_10315 = df[df['Customer ID'] == 'AA-10315']\n",
    "# print(cus_10315.head())\n",
    "cus_10315['Sales'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Sales'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.tsa.arima.model import ARIMA\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Group by month and aggregate sales data\n",
    "monthly_sales = df.groupby(df['Order Date'].dt.to_period('M'))['Sales'].sum()\n",
    "\n",
    "# Ensure 'Order Date' is in datetime format\n",
    "df['Order Date'] = pd.to_datetime(df['Order Date'])\n",
    "\n",
    "# Group by month and aggregate sales data (ensure proper datetime index)\n",
    "monthly_sales = df.groupby(df['Order Date'].dt.to_period('M'))['Sales'].sum()\n",
    "\n",
    "# Convert PeriodIndex to datetime for proper handling by ARIMA or Prophet\n",
    "monthly_sales.index = monthly_sales.index.to_timestamp()\n",
    "\n",
    "# Fit ARIMA model (p, d, q values can be adjusted)\n",
    "model = ARIMA(monthly_sales, order=(5, 1, 0))  # p, d, q can be tuned\n",
    "model_fit = model.fit()\n",
    "\n",
    "# Make predictions for the next 12 months\n",
    "forecast = model_fit.forecast(steps=12)\n",
    "\n",
    "plt.plot(monthly_sales.index, monthly_sales.values, label=\"Actual Sales\")\n",
    "plt.plot(pd.date_range(monthly_sales.index[-1], periods=13, freq='M')[1:], forecast, label=\"Forecasted Sales\", color='red')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Profitability Analysis : Identify the most/least profitable products, customers, and regions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Most and Least Profitable Products\n",
    "\n",
    "# Calculate total profit for each product\n",
    "product_profit = df.groupby('Product Name').agg({'Sales': 'sum', 'Profit': 'sum'}).reset_index()\n",
    "\n",
    "# Sort by profit to find the most and least profitable products\n",
    "product_profit_sorted = product_profit.sort_values(by='Profit', ascending=False)\n",
    "\n",
    "# Display the top and bottom products\n",
    "most_profitable_product = product_profit_sorted.head(10)\n",
    "least_profitable_product = product_profit_sorted.tail(10)\n",
    "\n",
    "print(\"Most Profitable Products:\")\n",
    "print(most_profitable_product)\n",
    "print(\"\\nLeast Profitable Products:\")\n",
    "print(least_profitable_product)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df['Product Name'] == 'Canon imageCLASS 2200 Advanced Copier']['Sales'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Most and Least Profitable Customers\n",
    "\n",
    "# Calculate total profit for each customer\n",
    "customer_profit = df.groupby('Customer ID').agg({'Sales': 'sum', 'Profit': 'sum'}).reset_index()\n",
    "\n",
    "# Sort by profit to find the most and least profitable customers\n",
    "customer_profit_sorted = customer_profit.sort_values(by='Profit', ascending=False)\n",
    "\n",
    "# Display the top and bottom customers\n",
    "most_profitable_customer = customer_profit_sorted.head(10)\n",
    "least_profitable_customer = customer_profit_sorted.tail(10)\n",
    "\n",
    "print(\"Most Profitable Customers:\")\n",
    "print(most_profitable_customer)\n",
    "print(\"\\nLeast Profitable Customers:\")\n",
    "print(least_profitable_customer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "customer_data = df[df['Customer ID'] == 'TC-20980']\n",
    "print(f\"Sales sum = {customer_data['Sales'].sum()}, Profit sum = {customer_data['Profit'].sum()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Most and Least Profitable Regions\n",
    "\n",
    "# Calculate total profit for each region\n",
    "region_profit = df.groupby('Region').agg({'Sales': 'sum', 'Profit': 'sum'}).reset_index()\n",
    "\n",
    "# Sort by profit to find the most and least profitable regions\n",
    "region_profit_sorted = region_profit.sort_values(by='Profit', ascending=False)\n",
    "\n",
    "# Display the top and bottom regions\n",
    "most_profitable_region = region_profit_sorted.head(10)\n",
    "least_profitable_region = region_profit_sorted.tail(10)\n",
    "\n",
    "print(\"Most Profitable Regions:\")\n",
    "print(most_profitable_region)\n",
    "print(\"\\nLeast Profitable Regions:\")\n",
    "print(least_profitable_region)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Sales = \" , df[df['Region'] == 'West']['Sales'].sum())\n",
    "print(\"Profit = \" , df[df['Region'] == 'West']['Profit'].sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Discount Optimization: Assess the impact of discounts on sales and profit to suggest optimal discount strategies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If not, you can calculate it as: (List Price - Sale Price) / List Price\n",
    "df['Discount Percentage'] = df['Discount'] * 100  # Assuming 'Discount' is a proportion (e.g., 0.1 for 10%)\n",
    "\n",
    "# Create discount ranges\n",
    "df['Discount Range'] = pd.cut(df['Discount Percentage'], bins=[0, 5, 10, 15, 20, 25, 30, 100], \n",
    "                              labels=[\"0-5%\", \"5-10%\", \"10-15%\", \"15-20%\", \"20-25%\", \"25-30%\", \"30%+\"])\n",
    "\n",
    "# Calculate average sales and profit for each discount range\n",
    "discount_analysis = df.groupby('Discount Range').agg({'Sales': 'mean', 'Profit': 'mean'}).reset_index()\n",
    "\n",
    "print(discount_analysis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Step 3: Plot the relationship between discount and average sales/profit\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "# Plot average sales and profit by discount range\n",
    "sns.barplot(x='Discount Range', y='Sales', data=discount_analysis, color='blue', alpha=0.6, label='Sales')\n",
    "sns.barplot(x='Discount Range', y='Profit', data=discount_analysis, color='green', alpha=0.6, label='Profit')\n",
    "\n",
    "plt.title(\"Impact of Discounts on Sales and Profit\")\n",
    "plt.xlabel(\"Discount Range (%)\")\n",
    "plt.ylabel(\"Value\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate correlation between Discount, Sales, and Profit\n",
    "correlation_matrix = df[['Discount Percentage', 'Sales', 'Profit']].corr()\n",
    "\n",
    "# Display the correlation matrix\n",
    "print(correlation_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Geographical Heatmaps: Visualize sales and profit distribution geographically."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group by geographic region\n",
    "geographical_data = df.groupby('Region').agg({'Sales': 'sum', 'Profit': 'sum'}).reset_index()\n",
    "\n",
    "print(geographical_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Anomaly Detection: Detect unusual trends in sales, profit, or discount using outlier detection techniques."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select relevant columns for anomaly detection\n",
    "anomaly_data = df[['Sales', 'Profit', 'Discount']]\n",
    "\n",
    "# Check for missing values and handle them if any\n",
    "print(anomaly_data.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import zscore\n",
    "\n",
    "# Calculate Z-scores for each column\n",
    "z_scores = anomaly_data.apply(zscore)\n",
    "\n",
    "# Define a threshold for anomalies (e.g., Z > 3 or Z < -3)\n",
    "threshold = 3\n",
    "anomalies = (z_scores.abs() > threshold)\n",
    "\n",
    "# Flag and display rows with anomalies\n",
    "anomalous_rows = df[anomalies.any(axis=1)]\n",
    "print(anomalous_rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import IsolationForest\n",
    "\n",
    "# Train an Isolation Forest model\n",
    "iso_forest = IsolationForest(contamination=0.05, random_state=42)\n",
    "df['Anomaly_Score'] = iso_forest.fit_predict(anomaly_data)\n",
    "\n",
    "# Identify anomalies (label -1 as anomalies)\n",
    "anomalies = df[df['Anomaly_Score'] == -1]\n",
    "print(anomalies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import DBSCAN\n",
    "\n",
    "# Fit DBSCAN on the data\n",
    "dbscan = DBSCAN(eps=0.5, min_samples=5)\n",
    "labels = dbscan.fit_predict(anomaly_data)\n",
    "\n",
    "# Add labels to the dataframe\n",
    "df['Cluster'] = labels\n",
    "\n",
    "# Identify outliers (label -1 as anomalies)\n",
    "outliers = df[df['Cluster'] == -1]\n",
    "print(outliers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Scatter plot to visualize anomalies\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.scatterplot(data=df, x='Sales', y='Profit', hue=(df['Anomaly_Score'] == -1), palette=['blue', 'red'])\n",
    "plt.title('Anomaly Detection in Sales and Profit')\n",
    "plt.legend(['Normal', 'Anomaly'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Shipping Efficiency: Analyze shipping times and modes to optimize delivery schedules."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert Order Date and Ship Date to datetime format with dayfirst=True\n",
    "df['Order Date'] = pd.to_datetime(df['Order Date'], dayfirst=True, errors='coerce')\n",
    "df['Ship Date'] = pd.to_datetime(df['Ship Date'], dayfirst=True, errors='coerce')\n",
    "\n",
    "# Check for any NaT (missing dates due to parsing issues)\n",
    "print(df[['Order Date', 'Ship Date']].isna().sum())\n",
    "\n",
    "# Calculate Delivery Time in days\n",
    "df['Delivery Time'] = (df['Ship Date'] - df['Order Date']).dt.days\n",
    "\n",
    "# Verify the result\n",
    "print(df[['Order Date', 'Ship Date', 'Delivery Time']].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group by Shipping Mode and calculate delivery statistics\n",
    "shipping_stats = df.groupby('Ship Mode').agg({\n",
    "    'Delivery Time': ['mean', 'median', 'max', 'std']\n",
    "}).reset_index()\n",
    "\n",
    "print(shipping_stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Boxplot of Delivery Time by Shipping Mode\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.boxplot(data=df, x='Ship Mode', y='Delivery Time', palette='Set2')\n",
    "plt.title('Delivery Time by Shipping Mode')\n",
    "plt.xlabel('Shipping Mode')\n",
    "plt.ylabel('Delivery Time (days)')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate thresholds for delays (e.g., > mean + 2*std)\n",
    "thresholds = shipping_stats['Delivery Time']['mean'] + 2 * shipping_stats['Delivery Time']['std']\n",
    "threshold_dict = dict(zip(shipping_stats['Ship Mode'], thresholds))\n",
    "\n",
    "# Flag delayed shipments\n",
    "df['Delayed'] = df.apply(\n",
    "    lambda row: row['Delivery Time'] > threshold_dict[row['Ship Mode']],\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "# Analyze delayed shipments\n",
    "delayed_orders = df[df['Delayed']]\n",
    "print(delayed_orders[['Ship Mode', 'Delivery Time']].head())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
